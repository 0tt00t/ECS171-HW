{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT Face Detector\n",
    "Below are two programs about face recognition obtained from ChatGPT using various techniques of machine learning. \n",
    "\n",
    "### Background Context\n",
    "##### K-Nearest Neighbors (KNN)\n",
    "A popular supervised machine learning algorithm used in regression and classification. The model prediction is based on the similarities between the unseen data from the test set and its k nearest neighbors in the training set.<br>\n",
    "- **Advantage:** simple and easy to implement <br>\n",
    "- **Disadvantage:** lazy learner (train while making prediction) so slower and more costly (memory)\n",
    "\n",
    "##### Convolutional Neural Network (CNN)\n",
    "A type of deep learning neural network architecture used for image and speech processing. By using multiple interconnected layers, they can extract useful features from the input data and use them to make predictions<br>\n",
    "- **Advantage:** multiple layers enable capture and recognize variations of data<br>\n",
    "- **Disadvantage:** high complexity (expensive to train and use)<br>\n",
    "\n",
    "### About the Dataset\n",
    "The file contains two set of data: training and testing in the `train` and `val` folders respectively. Each of them contains two set of randomly chosen images displaying two different type of facial expressions: happy and sad. \n",
    "\n",
    "Data size: \n",
    "|  | train | test |\n",
    "| --- | --- | --- |\n",
    "| happy men | 25 | 5 |\n",
    "| happy women | 25 | 5 |\n",
    "| sad men | 25 | 5 |\n",
    "| sad women | 25 | 5 |\n",
    "\n",
    "[Image Source](https://stock.adobe.com/)\n",
    "\n",
    "### Your tasks: \n",
    "KNN Model:\n",
    "- Explain what does `Accuracy` tells you.\n",
    "- Compute `precision` and `recall` and explain what they mean.\n",
    "<br>\n",
    "\n",
    "CNN Model:\n",
    "- Train the model with the given dataset. What could do potentially improves `accuracy` of the model?\n",
    "- Explain what does `loss` and `accuracy` tells you.\n",
    "- Compute TP, TN, FP, FN\n",
    "- Compute Precision and Recall\n",
    "- How much of the True Positive were Male? Female?\n",
    "- How much of the True Negative were Male? Female?\n",
    "- Create a bar chart to show these proportion in terms of percentage.\n",
    "\n",
    "### Format:\n",
    "- For questions that require justification, include all your answers in a (one) Markdown cell after each program.\n",
    "- For questions that require programming output, make sure it's clear what each output is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[0.99477124, 0.99607843, 0.99477124, ..., 0.38169935, 0.38562092,\n",
      "        0.38169935],\n",
      "       [0.14771242, 0.16078432, 0.21437909, ..., 0.44836605, 0.45098042,\n",
      "        0.58300656],\n",
      "       [0.34117648, 0.3503268 , 0.4366013 , ..., 0.7176471 , 0.72156864,\n",
      "        0.7163399 ],\n",
      "       ...,\n",
      "       [0.35816994, 0.3503268 , 0.31895426, ..., 0.21568628, 0.21568628,\n",
      "        0.17777778],\n",
      "       [0.19346406, 0.21045752, 0.29150328, ..., 0.6875817 , 0.6575164 ,\n",
      "        0.5908497 ],\n",
      "       [0.12418301, 0.09673203, 0.10849673, ..., 0.12941177, 0.16209151,\n",
      "        0.29150328]], dtype=float32), 'images': array([[[0.99477124, 0.99607843, 0.99477124, ..., 0.26797387,\n",
      "         0.23137255, 0.20130719],\n",
      "        [0.9973857 , 0.9973857 , 0.99607843, ..., 0.275817  ,\n",
      "         0.24052288, 0.20915033],\n",
      "        [0.98692805, 0.9751634 , 0.96732026, ..., 0.27058825,\n",
      "         0.24183007, 0.21960784],\n",
      "        ...,\n",
      "        [0.33594772, 0.2771242 , 0.20522876, ..., 0.41045752,\n",
      "         0.39869282, 0.37908497],\n",
      "        [0.30718955, 0.2509804 , 0.19477125, ..., 0.39607844,\n",
      "         0.39738563, 0.37385622],\n",
      "        [0.28496733, 0.24575163, 0.19738562, ..., 0.38169935,\n",
      "         0.38562092, 0.38169935]],\n",
      "\n",
      "       [[0.14771242, 0.16078432, 0.21437909, ..., 0.2248366 ,\n",
      "         0.1764706 , 0.13464053],\n",
      "        [0.16732027, 0.21830066, 0.24183007, ..., 0.22745098,\n",
      "         0.20915033, 0.16470589],\n",
      "        [0.18039216, 0.25490198, 0.2901961 , ..., 0.20130719,\n",
      "         0.20784314, 0.16209151],\n",
      "        ...,\n",
      "        [0.2875817 , 0.29803923, 0.29934642, ..., 0.48235294,\n",
      "         0.44183007, 0.45751634],\n",
      "        [0.29934642, 0.29803923, 0.29673204, ..., 0.4640523 ,\n",
      "         0.4392157 , 0.46797386],\n",
      "        [0.30457518, 0.3019608 , 0.29673204, ..., 0.44836605,\n",
      "         0.45098042, 0.58300656]],\n",
      "\n",
      "       [[0.34117648, 0.3503268 , 0.4366013 , ..., 0.5908497 ,\n",
      "         0.5908497 , 0.58300656],\n",
      "        [0.3529412 , 0.43790853, 0.52287585, ..., 0.5934641 ,\n",
      "         0.58431375, 0.5751634 ],\n",
      "        [0.40653598, 0.52287585, 0.579085  , ..., 0.62222224,\n",
      "         0.58300656, 0.5738562 ],\n",
      "        ...,\n",
      "        [0.29150328, 0.29542485, 0.27058825, ..., 0.654902  ,\n",
      "         0.7202614 , 0.70326805],\n",
      "        [0.2888889 , 0.2653595 , 0.2522876 , ..., 0.7267974 ,\n",
      "         0.72156864, 0.7137255 ],\n",
      "        [0.33071896, 0.27450982, 0.24836601, ..., 0.7176471 ,\n",
      "         0.72156864, 0.7163399 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.35816994, 0.3503268 , 0.31895426, ..., 0.16209151,\n",
      "         0.16470589, 0.19346406],\n",
      "        [0.36993465, 0.34379086, 0.30718955, ..., 0.16470589,\n",
      "         0.16209151, 0.17908497],\n",
      "        [0.3398693 , 0.29803923, 0.28235295, ..., 0.17254902,\n",
      "         0.15816994, 0.16862746],\n",
      "        ...,\n",
      "        [0.3633987 , 0.3633987 , 0.35816994, ..., 0.27058825,\n",
      "         0.33202615, 0.33071896],\n",
      "        [0.35555556, 0.35555556, 0.3633987 , ..., 0.19738562,\n",
      "         0.25490198, 0.24052288],\n",
      "        [0.31111112, 0.32287583, 0.3254902 , ..., 0.21568628,\n",
      "         0.21568628, 0.17777778]],\n",
      "\n",
      "       [[0.19346406, 0.21045752, 0.29150328, ..., 0.59607846,\n",
      "         0.5947712 , 0.5555556 ],\n",
      "        [0.21699347, 0.26013073, 0.36601308, ..., 0.5803922 ,\n",
      "         0.57124186, 0.56993467],\n",
      "        [0.23660131, 0.2888889 , 0.4117647 , ..., 0.5633987 ,\n",
      "         0.5281046 , 0.54640526],\n",
      "        ...,\n",
      "        [0.23660131, 0.23660131, 0.2379085 , ..., 0.6797386 ,\n",
      "         0.6248366 , 0.61045754],\n",
      "        [0.2379085 , 0.24183007, 0.24444444, ..., 0.703268  ,\n",
      "         0.6313726 , 0.6287582 ],\n",
      "        [0.23921569, 0.24052288, 0.23921569, ..., 0.6875817 ,\n",
      "         0.6575164 , 0.5908497 ]],\n",
      "\n",
      "       [[0.12418301, 0.09673203, 0.10849673, ..., 0.24705882,\n",
      "         0.1882353 , 0.1882353 ],\n",
      "        [0.12156863, 0.11111111, 0.13464053, ..., 0.27189544,\n",
      "         0.16732027, 0.16078432],\n",
      "        [0.13071896, 0.1267974 , 0.1254902 , ..., 0.3254902 ,\n",
      "         0.19346406, 0.1764706 ],\n",
      "        ...,\n",
      "        [0.17777778, 0.16601308, 0.1751634 , ..., 0.08496732,\n",
      "         0.09019608, 0.19607843],\n",
      "        [0.1633987 , 0.16209151, 0.17385621, ..., 0.09281046,\n",
      "         0.1267974 , 0.19869281],\n",
      "        [0.17908497, 0.19477125, 0.20522876, ..., 0.12941177,\n",
      "         0.16209151, 0.29150328]]], dtype=float32), 'target': array([5, 6, 3, ..., 5, 3, 5], dtype=int64), 'target_names': array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
      "       'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], dtype='<U17'), 'DESCR': \".. _labeled_faces_in_the_wild_dataset:\\n\\nThe Labeled Faces in the Wild face recognition dataset\\n------------------------------------------------------\\n\\nThis dataset is a collection of JPEG pictures of famous people collected\\nover the internet, all details are available on the official website:\\n\\n    http://vis-www.cs.umass.edu/lfw/\\n\\nEach picture is centered on a single face. The typical task is called\\nFace Verification: given a pair of two pictures, a binary classifier\\nmust predict whether the two images are from the same person.\\n\\nAn alternative task, Face Recognition or Face Identification is:\\ngiven the picture of the face of an unknown person, identify the name\\nof the person by referring to a gallery of previously seen pictures of\\nidentified persons.\\n\\nBoth Face Verification and Face Recognition are tasks that are typically\\nperformed on the output of a model trained to perform Face Detection. The\\nmost popular model for Face Detection is called Viola-Jones and is\\nimplemented in the OpenCV library. The LFW faces were extracted by this\\nface detector from various online websites.\\n\\n**Data Set Characteristics:**\\n\\n    =================   =======================\\n    Classes                                5749\\n    Samples total                         13233\\n    Dimensionality                         5828\\n    Features            real, between 0 and 255\\n    =================   =======================\\n\\nUsage\\n~~~~~\\n\\n``scikit-learn`` provides two loaders that will automatically download,\\ncache, parse the metadata files, decode the jpeg and convert the\\ninteresting slices into memmapped numpy arrays. This dataset size is more\\nthan 200 MB. The first load typically takes more than a couple of minutes\\nto fully decode the relevant part of the JPEG files into numpy arrays. If\\nthe dataset has  been loaded once, the following times the loading times\\nless than 200ms by using a memmapped version memoized on the disk in the\\n``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\\n\\nThe first loader is used for the Face Identification task: a multi-class\\nclassification task (hence supervised learning)::\\n\\n  >>> from sklearn.datasets import fetch_lfw_people\\n  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n  >>> for name in lfw_people.target_names:\\n  ...     print(name)\\n  ...\\n  Ariel Sharon\\n  Colin Powell\\n  Donald Rumsfeld\\n  George W Bush\\n  Gerhard Schroeder\\n  Hugo Chavez\\n  Tony Blair\\n\\nThe default slice is a rectangular shape around the face, removing\\nmost of the background::\\n\\n  >>> lfw_people.data.dtype\\n  dtype('float32')\\n\\n  >>> lfw_people.data.shape\\n  (1288, 1850)\\n\\n  >>> lfw_people.images.shape\\n  (1288, 50, 37)\\n\\nEach of the ``1140`` faces is assigned to a single person id in the ``target``\\narray::\\n\\n  >>> lfw_people.target.shape\\n  (1288,)\\n\\n  >>> list(lfw_people.target[:10])\\n  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\\n\\nThe second loader is typically used for the face verification task: each sample\\nis a pair of two picture belonging or not to the same person::\\n\\n  >>> from sklearn.datasets import fetch_lfw_pairs\\n  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\\n\\n  >>> list(lfw_pairs_train.target_names)\\n  ['Different persons', 'Same person']\\n\\n  >>> lfw_pairs_train.pairs.shape\\n  (2200, 2, 62, 47)\\n\\n  >>> lfw_pairs_train.data.shape\\n  (2200, 5828)\\n\\n  >>> lfw_pairs_train.target.shape\\n  (2200,)\\n\\nBoth for the :func:`sklearn.datasets.fetch_lfw_people` and\\n:func:`sklearn.datasets.fetch_lfw_pairs` function it is\\npossible to get an additional dimension with the RGB color channels by\\npassing ``color=True``, in that case the shape will be\\n``(2200, 2, 62, 47, 3)``.\\n\\nThe :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\\n3 subsets: the development ``train`` set, the development ``test`` set and\\nan evaluation ``10_folds`` set meant to compute performance metrics using a\\n10-folds cross validation scheme.\\n\\n.. topic:: References:\\n\\n * `Labeled Faces in the Wild: A Database for Studying Face Recognition\\n   in Unconstrained Environments.\\n   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\\n   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\\n   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\\n\\n\\nExamples\\n~~~~~~~~\\n\\n:ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\\n\"}\n",
      "\n",
      "Accuracy: 0.5813953488372093\n"
     ]
    }
   ],
   "source": [
    "#use KNN\n",
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the LFW dataset\n",
    "# downloads and returns the images of people's face and labels\n",
    "# only include people with at least 70 images in the dataset\n",
    "lfw = datasets.fetch_lfw_people(min_faces_per_person=70)\n",
    "\n",
    "print(lfw)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lfw.data, lfw.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a K-Nearest Neighbors classifier\n",
    "# n_neighbors: use the 5 nearest neighbors to make the predictions\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "# comparing the predicted labels (y_pred) with the true labels (y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "\n",
    "# accuracy gives the proportion of accurately predicted sample from the total number of sample\n",
    "# the closer to 1 the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5765068085804519\n",
      "Recall: 0.5813953488372093\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the ratio of correctly predicted samples to the total samples. The closer the accuracy is to 1, the better the model performs.\n",
    "\n",
    "Precision and recall are two metrics used to evaluate the performance of a classifier. Precision is the ratio of true positive predictions to the sum of true positive and false positive predictions. It represents the proportion of positive instances that are correctly identified by the model. Recall, on the other hand, is the ratio of true positive predictions to the sum of true positive and false negative predictions.It represents the proportion of actual positive instances that the model has correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 3s 109ms/step - loss: 0.7682 - accuracy: 0.4500 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 2s 106ms/step - loss: 0.6945 - accuracy: 0.3300 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 2s 108ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 2s 111ms/step - loss: 0.6896 - accuracy: 0.4900 - val_loss: 0.6816 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 2s 114ms/step - loss: 0.6645 - accuracy: 0.5300 - val_loss: 0.6742 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.6499 - accuracy: 0.6200 - val_loss: 0.7010 - val_accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 0.7018 - accuracy: 0.5500 - val_loss: 0.6762 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.6633 - accuracy: 0.6200 - val_loss: 0.6678 - val_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 2s 116ms/step - loss: 0.6297 - accuracy: 0.6600 - val_loss: 0.7799 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 2s 118ms/step - loss: 0.6076 - accuracy: 0.6000 - val_loss: 0.7803 - val_accuracy: 0.4500\n",
      "20/20 [==============================] - 1s 26ms/step\n",
      "Confusion Matrix for training set:\n",
      "[[44  6]\n",
      " [22 28]]\n",
      "\n",
      "True Positive (TP): 28\n",
      "True Negative (TN): 44\n",
      "False Positive (FP): 6\n",
      "False Negative (FN): 22\n",
      "4/4 [==============================] - 0s 27ms/step\n",
      "Confusion Matrix for test set:\n",
      "[[6 4]\n",
      " [7 3]]\n",
      "\n",
      "True Positive (TP): 3\n",
      "True Negative (TN): 6\n",
      "False Positive (FP): 4\n",
      "False Negative (FN): 7\n",
      "Precision for training set: 0.42857142857142855\n",
      "Recall for training set: 0.3\n",
      "Precision for validation set: 0.42857142857142855\n",
      "Recall for validation set: 0.3\n"
     ]
    }
   ],
   "source": [
    "#use CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the directory paths for the training and validation datasets\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "\n",
    "# Define the number of classes (happy and sad)\n",
    "num_classes = 2\n",
    "\n",
    "# Define the input shape of the images\n",
    "input_shape = (160, 160, 1)\n",
    "\n",
    "# Define the batch size for the data generators\n",
    "batch_size = 5\n",
    "\n",
    "# Define the data generators for the training and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=['happy', 'sad']\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=['happy', 'sad']\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples//batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('face_classification_model.h5')\n",
    "\n",
    "y_pred = model.predict(train_generator)\n",
    "y_true = train_generator.classes\n",
    "\n",
    "# Convert predicted labels to binary values (e.g., using a threshold)\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix for training set:\")\n",
    "print(cm)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "\n",
    "y_pred = model.predict(val_generator)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Convert predicted labels to binary values (e.g., using a threshold)\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix for test set:\")\n",
    "print(cm)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "train_precision = precision_score(y_true, y_pred_binary)\n",
    "train_recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(\"\\nPrecision for training set:\", train_precision)\n",
    "print(\"Recall for training set:\", train_recall)\n",
    "\n",
    "val_precision = precision_score(y_true, y_pred_binary)\n",
    "val_recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(\"Precision for validation set:\", val_precision)\n",
    "print(\"Recall for validation set:\", val_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 137ms/step - loss: 1.8402 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.6913 - accuracy: 0.6000 - val_loss: 0.6957 - val_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.6870 - accuracy: 0.4800 - val_loss: 0.7046 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6515 - accuracy: 0.5800 - val_loss: 0.8188 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6163 - accuracy: 0.6200 - val_loss: 0.7264 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.5916 - accuracy: 0.6600 - val_loss: 0.8964 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.6103 - accuracy: 0.5400 - val_loss: 0.7772 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.6109 - accuracy: 0.5800 - val_loss: 0.8529 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.5722 - accuracy: 0.7600 - val_loss: 0.8754 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.5666 - accuracy: 0.6400 - val_loss: 0.8642 - val_accuracy: 0.4000\n",
      "10/10 [==============================] - 0s 26ms/step\n",
      "Confusion Matrix for training set:\n",
      "[[24  1]\n",
      " [12 13]]\n",
      "\n",
      "True Positive (TP): 13\n",
      "True Negative (TN): 24\n",
      "False Positive (FP): 1\n",
      "False Negative (FN): 12\n",
      "2/2 [==============================] - 0s 28ms/step\n",
      "Confusion Matrix for test set:\n",
      "[[4 1]\n",
      " [5 0]]\n",
      "\n",
      "True Positive (TP): 0\n",
      "True Negative (TN): 4\n",
      "False Positive (FP): 1\n",
      "False Negative (FN): 5\n"
     ]
    }
   ],
   "source": [
    "#for male\n",
    "train_dir = 'train_male'\n",
    "val_dir = 'val_male'\n",
    "\n",
    "# Define the number of classes (happy and sad)\n",
    "num_classes = 2\n",
    "\n",
    "# Define the input shape of the images\n",
    "input_shape = (160, 160, 1)\n",
    "\n",
    "# Define the batch size for the data generators\n",
    "batch_size = 5\n",
    "\n",
    "# Define the data generators for the training and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=['happy', 'sad']\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=['happy', 'sad']\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples//batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('face_classification_model_male.h5')\n",
    "\n",
    "y_pred = model.predict(train_generator)\n",
    "y_true = train_generator.classes\n",
    "\n",
    "# Convert predicted labels to binary values (e.g., using a threshold)\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix for training set:\")\n",
    "print(cm)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "\n",
    "y_pred = model.predict(val_generator)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Convert predicted labels to binary values (e.g., using a threshold)\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix for test set:\")\n",
    "print(cm)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "train_precision = precision_score(y_true, y_pred_binary)\n",
    "train_recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(\"\\nPrecision for training set:\", train_precision)\n",
    "print(\"Recall for training set:\", train_recall)\n",
    "\n",
    "val_precision = precision_score(y_true, y_pred_binary)\n",
    "val_recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(\"Precision for validation set:\", val_precision)\n",
    "print(\"Recall for validation set:\", val_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 137ms/step - loss: 1.6972 - accuracy: 0.3200 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6954 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6930 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6915 - accuracy: 0.6400 - val_loss: 0.6904 - val_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6968 - accuracy: 0.5000 - val_loss: 0.6876 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6901 - accuracy: 0.7000 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "Confusion Matrix for training set:\n",
      "[[24  1]\n",
      " [14 11]]\n",
      "\n",
      "True Positive (TP): 11\n",
      "True Negative (TN): 24\n",
      "False Positive (FP): 1\n",
      "False Negative (FN): 14\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "Confusion Matrix for test set:\n",
      "[[4 1]\n",
      " [3 2]]\n",
      "\n",
      "True Positive (TP): 2\n",
      "True Negative (TN): 4\n",
      "False Positive (FP): 1\n",
      "False Negative (FN): 3\n"
     ]
    }
   ],
   "source": [
    "#for female\n",
    "train_dir = 'train_female'\n",
    "val_dir = 'val_female'\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "input_shape = (160, 160, 1)\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=['happy', 'sad']\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=['happy', 'sad']\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples//batch_size\n",
    ")\n",
    "\n",
    "model.save('face_classification_model_female.h5')\n",
    "\n",
    "\n",
    "y_pred = model.predict(train_generator)\n",
    "y_true = train_generator.classes\n",
    "\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "print(\"Confusion Matrix for training set:\")\n",
    "print(cm)\n",
    "\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "\n",
    "y_pred = model.predict(val_generator)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "print(\"Confusion Matrix for test set:\")\n",
    "print(cm)\n",
    "\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "print(\"\\nTrue Positive (TP):\", TP)\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "\n",
    "train_precision = precision_score(y_true, y_pred_binary)\n",
    "train_recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(\"\\nPrecision for training set:\", train_precision)\n",
    "print(\"Recall for training set:\", train_recall)\n",
    "\n",
    "val_precision = precision_score(y_true, y_pred_binary)\n",
    "val_recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "print(\"Precision for validation set:\", val_precision)\n",
    "print(\"Recall for validation set:\", val_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Improve: \n",
    "Data augmentation: Apply transformations to increase data diversity.\n",
    "Increase model complexity: Add more layers or filters.\n",
    "Regularization: Use dropout or L1/L2 regularization to reduce overfitting.\n",
    "Fine-tuning: Use pre-trained models and adapt them for your problem.\n",
    "Hyperparameter tuning: Optimize learning rate, batch size, etc.\n",
    "Early stopping: Stop training when validation performance plateaus.\n",
    "Increase dataset size: Collect more labeled data.\n",
    "Preprocessing: Normalize input data or apply other techniques.\n",
    "\n",
    "Loss: The difference between the model's predictions and true labels. Lower loss indicates better performance.\n",
    "Accuracy: The percentage of correct predictions made by the model. Higher accuracy means better predictions. Not ideal for imbalanced datasets.\n",
    "\n",
    "True Positive_Train M:13 F:13\n",
    "True Negtive_Train  M:15 F:20\n",
    "True Positive_Val M:0 F:2\n",
    "True Negtive_Val M:4 F:4\n",
    "True Positive_Total M:13 F:15\n",
    "True Negtive_Total M:19 F:24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAIAAAIhCAYAAADUyBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlHElEQVR4nO3deVhUdf//8dfIMoAsroAoKibue3Z7SxlaLrmV2SqWW5ZlVmSGmZWYBmrl0lezMlNbjDY0c0sstVxD0+pWbzP3UqLUwAVB4fz+8MfcjoACDgzMeT6u61yX8zlnzrzPLLyPrzlzjsUwDEMAAAAAAMAUKji7AAAAAAAAUHoIAgAAAAAAMBGCAAAAAAAATIQgAAAAAAAAEyEIAAAAAADARAgCAAAAAAAwEYIAAAAAAABMhCAAAAAAAAATIQgAAAAAAMBEihQEWCyWQk1r167VwYMH7cYqVKigqlWrqkePHtq0aVNJbU+R5dY5f/78ApepW7duobY7dx25tydNmpRnXfPnz5fFYtHWrVtLaIvyV5jtRPk0aNAg1a1b96rLvfnmmyX2+ufk5OjDDz9Ut27dFBgYKA8PD1WqVEn//ve/9dprr+nvv/8ukcd1lo4dO6pjx46l/riFfa2d6fvvv5fVatWhQ4dsf++uNjlim+rWratBgwYV677OfF4HDRpk91xUrFhRdevW1e2336558+YpMzOz2Otevny5YmNjr6m+Bx98UH369CnSfdhXYF8BZQ/7CqWPfYWCOWtfQZI2btyo2NhY/fPPP4VaPjY21q4OHx8f1apVS926ddP//d//6dSpU6VWS35efPFFtWnTRjk5OUW+r3tRFr68KU+YMEFr1qzRt99+azfepEkTnThxQpL0xBNPKCoqStnZ2dq5c6fGjx+vTp06adOmTWrdunWRC3aGRYsW2e2Mvfvuu5o7d65WrlypgIAA2/h1111nd79JkybpkUceUZUqVUqtVqAgb775pqpVq1bs/ywVJCMjQ3fccYdWr16t++67T2+88YZCQkKUnp6ujRs36tVXX9WXX36p77//3qGPi7LHMAxFR0fr4YcfVp06ddSzZ888faN9+/a6++679cwzz9jGrFbrNT/2okWL5O/vX6z7vvjii3rqqaeuuYbi8vb2tvXRjIwMHTlyRCtWrNDDDz+s119/XStXrlStWrWKvN7ly5dr1qxZ1xQGxMbGqlGjRvr22291yy23FOo+7CtcxL4CyiP2FVDSnLmvIF38z/f48eM1aNAgVapUqdD3y/1bnpWVpaNHj+qbb75RTEyMXn31VX311Vdq2bJlqdVyqVGjRmnmzJlasGCBBg8eXKT7FikI+Pe//213u3r16qpQoUKecUm25l67dm3b/BtvvFH169fXrbfeqjfffFNz5swpUrHOcvlOyMqVKyVJ119/vapVq5bvfTp37qy1a9fqlVde0euvv17iNaL8ycjIkJeXlywWi7NLuSbR0dFKSkrSwoUL1a9fP7t5vXr10gsvvKCPPvrISdVdnWEYOnfunLy9vZ1dSrm3cuVK/fjjj1q4cKGkiz2ievXqeZYLCgrKt2/kys7O1oULF4rU9K/lP4uX/8estOXXRwcMGKDBgwerV69euvvuu7V582an1Hbdddfptttu06RJkwodBLCvcBH7CnAE9hXKBvYVHMdR+wql7fK/5ffff79GjBihyMhI3X777fr1118dFlYURUBAgB544AFNmjTJdpRhYZX6OQJyX9BDhw5dcblPPvlEXbt2VY0aNeTt7a3GjRvrueee05kzZ+yWGzRokHx9ffXbb7+pR48e8vX1VWhoqJ555pk8h1QePXpU9957r/z8/BQQEKD77rtPKSkpjt3A/69hw4Z66KGHNGvWrKtu6+V++uknWSwWzZ07N8+8FStWyGKxaMmSJZKk3377TYMHD1Z4eLh8fHxUs2ZN9e7dW7/88stVH6egQ4dyD4G5lGEYevPNN9WqVSt5e3urcuXKuvvuu7V//3675bZv365evXopMDBQVqtVISEh6tmzp37//fer1rNy5UrdeuutCggIkI+Pjxo3bqz4+Hi7ZZYsWaL27dvLx8dHfn5+6tKlS54UMbf+n3/+Wffcc48CAgJUpUoVjRw5UhcuXNCePXt02223yc/PT3Xr1tWUKVPs7r927VpZLBZ9+OGHGjlypIKDg+Xt7a3IyEht377dbtmtW7fq/vvvV926deXt7a26deuqX79+eV7z3MOeVq1apSFDhqh69ery8fGxvUc/+eQTtW/fXhUrVpSvr6+6deuW57Fy19OwYUNZrVY1btxY77///lWfV+niIas7d+7UunXr8j3E6vDhw3rggQdsr1vjxo31+uuvX/Uwo2PHjum9995Tz5498zT2XD4+Pnr44Yftxgr7furYsaOaNWum5ORkdejQQT4+PqpXr54mTZqUp7b09HSNGjVKYWFh8vT0VM2aNRUdHZ3nb4bFYtGIESP01ltvqXHjxrJarVqwYIEkafz48WrXrp2qVKkif39/tWnTRnPnzpVhGFd8HvLTp08f1alTJ9/nsF27dmrTpo3t9qxZs3TzzTcrMDBQFStWVPPmzTVlyhSdP3/+io9xpcN4LRZLnm+C9+7dq6ioKLvXedasWXbL5OTkaOLEiWrYsKG8vb1VqVIltWjRQjNmzLjqNs+ePVs33HCDGjZseNVlL9+GKVOmaOLEiQoLC5PVatWaNWt07tw5PfPMM2rVqpXtc9y+fXt9+eWXedZz+U8Dcj/HH3/8scaOHauQkBD5+/urc+fO2rNnj9198/tbmPs++eCDD9S4cWP5+PioZcuWWrp0aZ7H/vLLL9WiRQtZrVbVq1dPM2bMyPfvaFF17dpVDz/8sLZs2aLvvvvONl6Y/jho0CDba3vpIY0HDx6UVLT33IMPPqjVq1dr375917Q9RcG+wtWxr8C+AvsKF7Gv4Pr7Co6qKzY2Vs8++6wkKSwszO6nasXRsmVLjR07VocPH9Ynn3xiG09KStIdd9yhWrVqycvLS/Xr19ewYcPsfv5ytVoK29+ki336119/1Zo1a4pUf6kHAb/99psk5Zv8XGrv3r3q0aOH7bC66Ohoffrpp+rdu3eeZc+fP6/bb79dt956q7788ksNGTJE06ZN0+TJk23LZGRkqHPnzlq1apXi4+P12WefKTg4WPfdd59jN/ASsbGxcnNz04svvlik+7Vs2VKtW7fWvHnz8sybP3++AgMD1aNHD0kXd1iqVq2qSZMmaeXKlZo1a5bc3d3Vrl27PDu712LYsGGKjo5W586dtXjxYr355pvauXOnIiIi9Oeff0qSzpw5oy5duujPP//UrFmzlJSUpOnTp6t27dpX/f3M3Llz1aNHD+Xk5Oitt97SV199pSeffNJup2DhwoW644475O/vr48//lhz587VyZMn1bFjR61fvz7POu+99161bNlSX3zxhR5++GFNmzZNTz/9tPr06aOePXtq0aJFuuWWWzR69GglJibmuf/zzz+v/fv3691339W7776ro0ePqmPHjnYN6ODBg2rYsKGmT5+ur7/+WpMnT9axY8d0ww035PtbtyFDhsjDw0MffPCBPv/8c3l4eCguLk79+vVTkyZN9Omnn+qDDz7QqVOn1KFDB+3atct23/nz52vw4MFq3LixvvjiC73wwguaMGFCnsNt87No0SLVq1dPrVu31qZNm7Rp0yYtWrRIkvTXX38pIiJCq1at0oQJE7RkyRJ17txZo0aN0ogRI6643jVr1ujChQu6/fbbr1rDpQrzfsqVkpKi/v3764EHHtCSJUvUvXt3jRkzRh9++KFtmbNnzyoyMlILFizQk08+qRUrVmj06NGaP3++br/99jzNefHixZo9e7Zeeuklff311+rQoYOki6/nsGHD9OmnnyoxMVF9+/bVE088oQkTJhRp+6SLr/Xhw4fzvD7//e9/9cMPP9gdvrVv3z5FRUXpgw8+0NKlS/XQQw/p1Vdf1bBhw4r8uAXZtWuXbrjhBv3nP//R66+/rqVLl6pnz5568sknNX78eNtyU6ZMUWxsrPr166dly5bpk08+0UMPPXTV369lZWVp9erV6tSpU7Hqe+ONN/Ttt9/qtdde04oVK9SoUSNlZmbqxIkTGjVqlBYvXqyPP/5YN910k/r27VvoHdvnn39ehw4d0rvvvqt33nlHe/fuVe/evZWdnX3V+y5btkwzZ87Uyy+/rC+++EJVqlTRnXfeafc3YOXKlerbt6+qVq2qTz75RFOmTNHHH39s22G8VrmfrUuDgML0xxdffFF33323JNk+85s2bVKNGjUkFe0917FjRxmGoeXLlztkmwqDfYWrY1+BfQX2Ff6HfQXHKKv7Co6qa+jQoXriiSckSYmJibb3+aWBS1Hl16f37dun9u3ba/bs2Vq1apVeeuklbdmyRTfddJMtuLlaLUXpb9dff718fX21bNmyohVvXIOBAwcaFStWzHfegQMHDEnG5MmTjfPnzxvnzp0ztm3bZtxwww2GJGPZsmWFfpycnBzj/Pnzxrp16wxJxk8//WRXgyTj008/tbtPjx49jIYNG9puz54925BkfPnll3bLPfzww4YkY968eYWuZ9y4cYYk46+//sp3viTj8ccfNwzDMMaOHWtUqFDBVvO8efMMSUZycvIVH+ONN94wJBl79uyxjZ04ccKwWq3GM888U+D9Lly4YGRlZRnh4eHG008/bRvPfT0u3c6BAwcaderUKXD7cm3atMmQZLz++ut2yx05csTw9vY2YmJiDMMwjK1btxqSjMWLF19x2y536tQpw9/f37jpppuMnJycfJfJzs42QkJCjObNmxvZ2dl29w0MDDQiIiLy1H95va1atTIkGYmJibax8+fPG9WrVzf69u1rG1uzZo0hyWjTpo1dPQcPHjQ8PDyMoUOHFrgtFy5cME6fPm1UrFjRmDFjhm0893UfMGCA3fKHDx823N3djSeeeCLPcxIcHGzce++9dttfUE35vY6Xa9q0qREZGZln/LnnnjMkGVu2bLEbf+yxxwyLxWL3HrzcpEmTDEnGypUr88w7f/683ZSrsO8nwzCMyMjIfGtr0qSJ0a1bN9vt+Ph4o0KFCnk+V59//rkhyVi+fLltTJIREBBgnDhxosDtMoyLz/n58+eNl19+2ahatard8x4ZGZnvc3n59gcFBRlRUVF24zExMYanp6fx999/X/Fx33//fcPNzc2uzss/s/l9ri/dznHjxtlud+vWzahVq5aRlpZmt9yIESMMLy8v2+P06tXLaNWq1RW3LT9btmwxJBkJCQlXXO7Sv4+XbsN1111nZGVlXfG+Fy5cMM6fP2889NBDRuvWre3m1alTxxg4cKDtdu7nuEePHnbLffrpp4YkY9OmTbax/P4WSjKCgoKM9PR021hKSopRoUIFIz4+3jZ2ww03GKGhoUZmZqZt7NSpU0bVqlXt/o4W5Ep91DAMY/fu3YYk47HHHst3/pX64+OPP16oGq70nstVs2ZN47777rvquvLDvgL7Cuwr2GNf4X/YV2BfIT+X7ys4sq5XX33VkGQcOHCgUDVf7W95RkaGIcno3r17vvNze9OhQ4fy9JfC1nKl/pbrxhtvNNq1a1eobcpV4kcEjB49Wh4eHvLy8tL111+vw4cP6+2337al1AXZv3+/oqKiFBwcLDc3N3l4eCgyMlKStHv3brtlLRZLnnSkRYsWdodcrVmzRn5+fnnSyKioqGvZvKuKiYlRlSpVNHr06CLdr3///rJarXaH8Xz88cfKzMy0SwcvXLiguLg4NWnSRJ6ennJ3d5enp6f27t2b53kqrqVLl8piseiBBx7QhQsXbFNwcLBatmxpO4Slfv36qly5skaPHq233nrLLqG+ko0bNyo9PV3Dhw8v8FDaPXv26OjRo3rwwQdVocL/3ra+vr666667tHnzZp09e9buPr169bK73bhxY1ksFnXv3t025u7urvr16+d7SGZUVJRdPXXq1FFERITdYTenT5/W6NGjVb9+fbm7u8vd3V2+vr46c+ZMvs//XXfdZXf766+/1oULFzRgwAC759bLy0uRkZG25zZ3+wuq6Vp8++23atKkif71r3/ZjQ8aNEiGYRTqW4TL7dixQx4eHnZT7rcehX0/5QoODs5T2+Wf76VLl6pZs2Zq1aqV3Tq7deuW7yFft9xyiypXrpzvc9G5c2cFBATY/u689NJLOn78uFJTU4v0HLi7u+uBBx5QYmKi0tLSJF387fsHH3ygO+64Q1WrVrUtu337dt1+++2qWrWq7XEHDBig7Oxs/frrr0V63PycO3dO33zzje688075+PjYPUc9evTQuXPnbL9B/9e//qWffvpJw4cP19dff6309PRCPcbRo0clSYGBgcWq8fbbb5eHh0ee8c8++0w33nijfH195e7uLg8PD82dO7fQf98u/5vfokULSVc/5FySOnXqJD8/P9vtoKAgBQYG2u575swZbd26VX369JGnp6dtOV9f33wT++Iw8jnUtCj9sSBFfc8FBgbqjz/+uLaNuQL2FdhXuBr2FdhXYF/BnPsKpVHXtcivT6empurRRx9VaGiobd+lTp06kgrfp4va64vTp0s8CHjqqaeUnJysbdu2ad++fTp27JgeeeSRK97n9OnT6tChg7Zs2aKJEydq7dq1Sk5Oth2SlZGRYbe8j4+PvLy87MasVqvOnTtnu338+HEFBQXleazg4ODiblqh+Pv764UXXtDKlSuL9LuNKlWq6Pbbb9f7779vO4R1/vz5+te//qWmTZvalhs5cqRefPFF9enTR1999ZW2bNmi5ORktWzZMs/zVFx//vmnDMNQUFBQnj/Ymzdvtv3RDggI0Lp169SqVSs9//zzatq0qUJCQjRu3Lgr/n7pr7/+kqQrnhX7+PHjkmQ7rPVSISEhysnJ0cmTJ+3GLz8Ds6enZ77vFU9PT7v3Sq783hvBwcG2WqSLOwAzZ87U0KFD9fXXX+uHH35QcnKyqlevnu/zf3n9uYe23XDDDXme208++cT23OY+ZkE1XYvjx48X+Lxe+tj5qV27tqS8/6lq2LChkpOTlZycnOc3f4V9P+W6tAnmslqtds/vn3/+qZ9//jnP+vz8/GQYRp515re9P/zwg7p27SpJmjNnjjZs2KDk5GSNHTtWUt6/O4UxZMgQnTt3TgkJCZIu7swdO3bMbgf98OHD6tChg/744w/NmDFD33//vZKTk22/e3PE5/j48eO6cOGC/u///i/Pc5T7H63c52jMmDF67bXXtHnzZnXv3l1Vq1bVrbfeetXLmOXWefnnq7Dye00SExN17733qmbNmvrwww+1adMmJScn257Xwrj8/ZN7Ip/CPK9Xe++dPHnS9l6+XH5jxZH72cr9PBa1P+anOO85Ly8vh/WU/LCvwL4C+wr/w74C+wrsK5RuXdfi8j6dk5Ojrl27KjExUTExMfrmm2/0ww8/2MKKwrxWxen1xenTRbpqQHHUqlVLbdu2LdJ9vv32Wx09elRr1661JR+Srukai1WrVtUPP/yQZ7ykTgB0qccee0wzZszQ6NGj9dhjjxX6foMHD9Znn32mpKQk1a5dW8nJyZo9e7bdMh9++KEGDBiguLg4u/G///77qpeh8PLyyvca1Zf/IaxWrZosFovtmp+Xu3SsefPmSkhIkGEY+vnnnzV//ny9/PLL8vb21nPPPZdvHbm/Ab3SSYJy/8AfO3Ysz7yjR4+qQoUK+aa21yK/90ZKSoqtlrS0NC1dulTjxo2z27bc3zXn5/JvMXLPPvr555/bksL85D5mQTVdi6pVqxb4vF5aY346duwod3d3LVmyxG6n3dvb2/a5v/zkakV5PxVWtWrV5O3trffee6/A+ZfK79ukhIQEeXh4aOnSpXYNavHixUWuJ1futyfz5s3TsGHDNG/ePIWEhNh2InLXf+bMGSUmJtq9B3bs2HHV9efWefnn+PIdssqVK8vNzU0PPvigHn/88XzXFRYWJunitxMjR47UyJEj9c8//2j16tV6/vnn1a1bNx05ckQ+Pj753j/3OS7ovX81+b0mH374ocLCwvTJJ5/Yzc/v75YzVK5cWRaLJc9vVSXH9Zbck73lXovaEf2xOO+5EydOlOh1qdlXYF+BfYX/YV+BfQX2FUq3rmtxeZ/+z3/+o59++knz58/XwIEDbcvlnvumMIrT306cOHHFz2F+Sv1kgYWR+8G7/EP+9ttvF3udnTp10qlTp2wvVq7cS1eUJE9PT02cOFHJycn67LPPCn2/rl27qmbNmpo3b57mzZsnLy+vPGdbtVgseZ6nZcuWFerQkLp16yo1NdVuJzYrK0tff/213XK9evWSYRj6448/1LZt2zxT8+bN86zbYrGoZcuWmjZtmipVqqQff/yxwDoiIiIUEBCgt956q8AzrjZs2FA1a9bUwoUL7ZY5c+aMvvjiC9vZgR3p448/tnusQ4cOaePGjbYPusVikWEYeZ7/d999t1AnIpOkbt26yd3dXfv27cv3uc1tkA0bNlSNGjUKrKkwLk/Gc916663atWtXntfo/fffl8ViueIJXWrUqKEhQ4Zo2bJltiT7aorzfirMOvft26eqVavmu87C/AfGYrHI3d1dbm5utrGMjAx98MEHRa7nUoMHD9aWLVu0fv16ffXVVxo4cKDdY+T3984wjEJdMi0oKEheXl76+eef7cYvP6u+j4+POnXqpO3bt6tFixb5Pkf5fZtSqVIl3X333Xr88cd14sQJ2xnn89O4cWNJcuiZ5S0Wizw9Pe12xlJSUvK9aoAzVKxYUW3bttXixYuVlZVlGz99+nS+VxcoqqSkJL377ruKiIjQTTfdJKlo/bGgox+K+p67cOGCjhw5oiZNmhRzS0oG+woXsa/wP+wrsK9wtXWyr/A/5WVfwdF1FeXIwKv56aefFBcXp7p16+ree++VVHJ9uqB15Nq/f3+R+3SJHxFQHBEREapcubIeffRRjRs3Th4eHvroo4/0008/FXudAwYM0LRp0zRgwAC98sorCg8P1/Lly/M0spLSr18/29mwC8vNzU0DBgzQ1KlT5e/vr759+yogIMBumV69emn+/Plq1KiRWrRooW3btunVV1+94qFzue677z699NJLuv/++/Xss8/q3LlzeuONN/I0phtvvFGPPPKIBg8erK1bt+rmm29WxYoVdezYMa1fv17NmzfXY489pqVLl+rNN99Unz59VK9ePRmGocTERP3zzz/q0qVLgXX4+vrq9ddf19ChQ9W5c2c9/PDDCgoK0m+//aaffvpJM2fOVIUKFTRlyhT1799fvXr10rBhw5SZmalXX31V//zzjyZNmlTo57WwUlNTdeedd+rhhx9WWlqaxo0bJy8vL40ZM0bSxUM5b775Zr366quqVq2a6tatq3Xr1mnu3LlX/YYlV926dfXyyy9r7Nix2r9/v2677TZVrlxZf/75p3744QdVrFhR48ePV4UKFTRhwgQNHTrUVtM///yj2NjYQh/ul/sNzCeffKJ69erJy8tLzZs319NPP633339fPXv21Msvv6w6depo2bJlevPNN/XYY4+pQYMGV1zv9OnTdeDAAfXv319LlizRHXfcoZCQEJ09e1b//e9/lZCQIC8vL9vvvwv7fiqK6OhoffHFF7r55pv19NNPq0WLFsrJydHhw4e1atUqPfPMM2rXrt0V19GzZ09NnTpVUVFReuSRR3T8+HG99tpr13xN2H79+mnkyJHq16+fMjMz7S5xJ0ldunSRp6en+vXrp5iYGJ07d06zZ8/Oc/hqfnJ/P/nee+/puuuuU8uWLfXDDz/k+5+WGTNm6KabblKHDh302GOPqW7dujp16pR+++03ffXVV7bfd/bu3VvNmjVT27ZtVb16dR06dEjTp09XnTp1FB4eXmAttWrVUr169bR582Y9+eSTRXuSCtCrVy8lJiZq+PDhuvvuu3XkyBFNmDBBNWrU0N69ex3yGNfq5ZdfVs+ePdWtWzc99dRTys7O1quvvipfX99Cf+ORk5NjO2QwMzNThw8f1ooVK/Tpp5+qcePG+vTTT23LFqU/5u4oT548Wd27d5ebm5tatGhR5Pfczz//rLNnzxb7ihAlhX2Fi9hXYF+BfYXCYV+h/O4rOLKu3N44Y8YMDRw4UB4eHmrYsKHdOYHys23bNgUEBOj8+fM6evSovvnmG33wwQcKDAzUV199ZTtXUKNGjXTdddfpueeek2EYqlKlir766islJSXlWWdBtRS1vx0/flx79+61XYWg0Ip0asHLFOZMwK+++mqx1r1x40ajffv2ho+Pj1G9enVj6NChxo8//pjv2Wzzq+Hys9kahmH8/vvvxl133WX4+voafn5+xl133WVs3LixRM8EfKlVq1YZkgp1JuBcv/76q+0+SUlJeeafPHnSeOihh4zAwEDDx8fHuOmmm4zvv/8+z5lKCzpj6PLly41WrVoZ3t7eRr169YyZM2fm+9wZhmG89957Rrt27YyKFSsa3t7exnXXXWcMGDDA2Lp1q2EYhvHf//7X6Nevn3HdddcZ3t7eRkBAgPGvf/3LmD9/fqG2dfny5UZkZKRRsWJFw8fHx2jSpIkxefJku2UWL15stGvXzvDy8jIqVqxo3HrrrcaGDRvslino9SnovRIZGWk0bdrUdjv3TMAffPCB8eSTTxrVq1c3rFar0aFDB9u25sp9T1WuXNnw8/MzbrvtNuM///lPnjOYX+0M0IsXLzY6depk+Pv7G1ar1ahTp45x9913G6tXr7Zb7t133zXCw8MNT09Po0GDBsZ7771X4BmdL3fw4EGja9euhp+fnyHJ7j6HDh0yoqKijKpVqxoeHh5Gw4YNjVdffdXurMtXkp2dbbz//vtGly5djGrVqhnu7u621//FF180fv/99zz3udr7yTDyvja58tvm06dPGy+88ILRsGFDw9PT0wgICDCaN29uPP3000ZKSoptuYI+n7k1NWzY0LBarUa9evWM+Ph4Y+7cuXnO6FqYMwFfKioqypBk3HjjjfnO/+qrr4yWLVsaXl5eRs2aNY1nn33WWLFihSHJWLNmzRW3Oy0tzRg6dKgRFBRkVKxY0ejdu7dx8ODBPGcCNoyLfweGDBli1KxZ0/Dw8DCqV69uREREGBMnTrQt8/rrrxsRERFGtWrVDE9PT6N27drGQw89ZBw8ePCq2/niiy8alStXNs6dO1fgMpc//1frFZMmTTLq1q1rWK1Wo3HjxsacOXPy/RtV0FUDPvvsszzPQX59JL+rBuT3Prn8cQzDMBYtWmQ0b97c9nxNmjTJePLJJ43KlSsX+Dxc+ti5f+MlGd7e3kbt2rWN3r17G++9957d1QhyFbY/ZmZmGkOHDjWqV69uWCwWu/dxYd9zhnHxda1WrdoVX9erbSP7Cnmxr8C+AvsK7Ctcin2F/8nv+XdkXWPGjDFCQkKMChUq5Nv3LpX7tyJ3slqtRo0aNYyuXbsaM2bMsLu6UK5du3YZXbp0Mfz8/IzKlSsb99xzj3H48OF8n++CailsfzMMw5g7d67h4eFh9x4uDIthFHB8FWBSa9euVadOnfTZZ5/ZrsMN4OqOHj2qsLAwvf/++yV63fWy7vz582rVqpVq1qypVatWObuca5Kdna369esrKipKr7zyirPLAcoM9hWA4mFfwfE6dOig2rVr66OPPirS/crkOQIAAOVPSEiIoqOj9corrygnJ8fZ5ZSahx56SAkJCVq3bp0++eQTde3aVbt371ZMTIyzS7tmH374oU6fPq1nn33W2aUAAFyAWfcVSsp3332n5ORkTZgwocj3LZPnCAAAlE8vvPCCfHx89Mcffyg0NNTZ5ZSKU6dOadSoUfrrr7/k4eGhNm3aaPny5ercubOzS7tmOTk5+uijjwr9W2YAAK7GjPsKJeX48eN6//33Va9evSLfl58GAAAAAABgIvw0AAAAlJi6devKYrHkmXKvB20YhmJjYxUSEiJvb2917NhRO3fudHLVAAC4NoIAAABQYpKTk3Xs2DHblHsJpXvuuUeSNGXKFE2dOlUzZ85UcnKygoOD1aVLF506dcqZZQMA4NL4aQAAACg10dHRWrp0qfbu3SvpfyeOGj16tCQpMzNTQUFBmjx5soYNG+bMUgEAcFkuf7LAnJwcHT16VH5+frJYLM4uBwAAGYahU6dOKSQkRBUqmOfgvKysLH344YcaOXKkLBaL9u/fr5SUFHXt2tW2jNVqVWRkpDZu3FhgEJCZmanMzEzb7ZycHJ04cUJVq1al1wMAyoSy3utdPgg4evQoZ6MEAJRJR44cUa1atZxdRqlZvHix/vnnHw0aNEiSlJKSIkkKCgqyWy4oKEiHDh0qcD3x8fEaP358idUJAICjlNVe7/JBgJ+fn6SLL4C/v7+TqwEAQEpPT1doaKitR5nF3Llz1b17d4WEhNiNX/4tvmEYV/xmf8yYMRo5cqTtdlpammrXrk2vBwCUGWW917t8EJC7I+Hv78/OAQCgTDHTYeyHDh3S6tWrlZiYaBsLDg6WdPHIgBo1atjGU1NT8xwlcCmr1Sqr1ZpnnF4PAChrymqvL3s/VgAAAC5n3rx5CgwMVM+ePW1jYWFhCg4Otl1JQLp4HoF169YpIiLCGWUCAGAKLn9EAAAAcK6cnBzNmzdPAwcOlLv7/3Y9LBaLoqOjFRcXp/DwcIWHhysuLk4+Pj6KiopyYsUAALg2ggAAAFCiVq9ercOHD2vIkCF55sXExCgjI0PDhw/XyZMn1a5dO61atarM/qYSAABXYDEMw3B2ESUpPT1dAQEBSktLK/B3g4Zh6MKFC8rOzi7l6pDLzc1N7u7uZfY3NADgSIXpTSg8en354eHhITc3N2eXAQAlrqz3etMfEZCVlaVjx47p7Nmzzi7F9Hx8fFSjRg15eno6uxQAgAuh15cdFotFtWrVkq+vr7NLAQBTM3UQkJOTowMHDsjNzU0hISHy9PTkG2knMAxDWVlZ+uuvv3TgwAGFh4erQgXOYwkAuHb0+rLDMAz99ddf+v333xUeHs6RAQDgRKYOArKyspSTk6PQ0FD5+Pg4uxxT8/b2loeHhw4dOqSsrCx5eXk5uyQAgAug15ct1atX18GDB3X+/HmCAABwIr52lfj2uYzgdQAAlBR6TNnA0RgAUDbQFQEAAAAAMBGCAAAAAAAATMTU5wi4krrPLSu1xzo4qWepPVa+j3/woMLCwrR9+3a1atXKqbUAAFBaSrPXS87t9/R6AMClOCKgnBo0aJAsFoseffTRPPOGDx8ui8WiQYMGlX5hAADAIej1AICSQhBQjoWGhiohIUEZGRm2sXPnzunjjz9W7dq1nVgZAABwBHo9AKAkEASUY23atFHt2rWVmJhoG0tMTFRoaKhat25tG1u5cqVuuukmVapUSVWrVlWvXr20b9++K657165d6tGjh3x9fRUUFKQHH3xQf//9d4ltCwAAyIteDwAoCQQB5dzgwYM1b9482+333ntPQ4YMsVvmzJkzGjlypJKTk/XNN9+oQoUKuvPOO5WTk5PvOo8dO6bIyEi1atVKW7du1cqVK/Xnn3/q3nvvLdFtAQAAedHrAQCOxskCy7kHH3xQY8aM0cGDB2WxWLRhwwYlJCRo7dq1tmXuuusuu/vMnTtXgYGB2rVrl5o1a5ZnnbNnz1abNm0UFxdnG3vvvfcUGhqqX3/9VQ0aNCix7QEAAPbo9QAARyMIKOeqVaumnj17asGCBTIMQz179lS1atXsltm3b59efPFFbd68WX///bft24HDhw/nu3Owbds2rVmzRr6+vnnm7du3j50DAABKEb0eAOBoBAEuYMiQIRoxYoQkadasWXnm9+7dW6GhoZozZ45CQkKUk5OjZs2aKSsrK9/15eTkqHfv3po8eXKeeTVq1HBs8QAA4Kro9QAARyIIcAG33XabrdF369bNbt7x48e1e/duvf322+rQoYMkaf369VdcX5s2bfTFF1+obt26cnfnLQIAgLPR6wEAjsRffhfg5uam3bt32/59qcqVK6tq1ap65513VKNGDR0+fFjPPffcFdf3+OOPa86cOerXr5+effZZVatWTb/99psSEhI0Z86cPI8BlLa6zy1zdgnl1kGvKGeXUL7Fpjm7AphUuer1R7cXPO+CIf3zlzTzHun0keI/hqvib4wd+n3x0e+vgUk+hwQBBTg4qaezSygSf3//fMcrVKighIQEPfnkk2rWrJkaNmyoN954Qx07dixwXSEhIdqwYYNGjx6tbt26KTMzU3Xq1NFtt92mChW40AQAwDXQ6+n1AGBWBAHl1Pz58684f/HixbZ/d+7cWbt27bKbbxiG7d9169a1uy1J4eHhdtcsBgAApYteDwAoKUS+AAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmIi7swsos2IDSvGx0krvsUpQ3bp1FR0drejoaGeXAgDA1ZVmr5dcot/T6wHANXBEQDk1aNAgWSyWPNNvv/3m7NIAAIAD0OsBACWFIwLKsdtuu03z5s2zG6tevbqTqgEAAI5GrwcAlASOCCjHrFargoOD7SY3Nzd99dVXuv766+Xl5aV69epp/PjxunDhgu1+FotFb7/9tnr16iUfHx81btxYmzZt0m+//aaOHTuqYsWKat++vfbt22e7z759+3THHXcoKChIvr6+uuGGG7R69eor1peWlqZHHnlEgYGB8vf31y233KKffvqpxJ4PAABcTbns9Tt/LbHnAwDgGAQBLubrr7/WAw88oCeffFK7du3S22+/rfnz5+uVV16xW27ChAkaMGCAduzYoUaNGikqKkrDhg3TmDFjtHXrVknSiBEjbMufPn1aPXr00OrVq7V9+3Z169ZNvXv31uHDh/OtwzAM9ezZUykpKVq+fLm2bdumNm3a6NZbb9WJEydK7gkAAMDFlflef9+jOnGy/J8PAQBcGT8NKMeWLl0qX19f2+3u3bvrzz//1HPPPaeBAwdKkurVq6cJEyYoJiZG48aNsy07ePBg3XvvvZKk0aNHq3379nrxxRfVrVs3SdJTTz2lwYMH25Zv2bKlWrZsabs9ceJELVq0SEuWLLHbici1Zs0a/fLLL0pNTZXVapUkvfbaa1q8eLE+//xzPfLIIw58JgAAcE3lstd/8Yk+X7ZajzxwlwOfCQCAIxEElGOdOnXS7NmzbbcrVqyo+vXrKzk52e5bgezsbJ07d05nz56Vj4+PJKlFixa2+UFBQZKk5s2b242dO3dO6enp8vf315kzZzR+/HgtXbpUR48e1YULF5SRkVHgtwTbtm3T6dOnVbVqVbvxjIwMu8MQAQBAwcptrz/0+7VvPACgxBAElGO5OwOXysnJ0fjx49W3b988y3t5edn+7eHhYfu3xWIpcCwnJ0eS9Oyzz+rrr7/Wa6+9pvr168vb21t33323srKy8q0tJydHNWrU0Nq1a/PMq1SpUuE2EAAAkyuXvf7PnaoU4Ff4jQQAlDqCABfTpk0b7dmzJ89Ow7X6/vvvNWjQIN15552SLv6O8ODBg1esIyUlRe7u7qpbt65DawEAwMzKfK/3OeXQugAAjkcQ4GJeeukl9erVS6GhobrnnntUoUIF/fzzz/rll180ceLEYq+3fv36SkxMVO/evWWxWPTiiy/avkHIT+fOndW+fXv16dNHkydPVsOGDXX06FEtX75cffr0Udu2bYtdCwAAZlbme/0n76nPbZ3UtmWTYtcCAChZBAEFiS2fZ7vt1q2bli5dqpdffllTpkyRh4eHGjVqpKFDh17TeqdNm6YhQ4YoIiJC1apV0+jRo5Wenl7g8haLRcuXL9fYsWM1ZMgQ/fXXXwoODtbNN99s+50iAABORa+347Bef0MzBVWrck21AABKlsUwDMPZRZSk9PR0BQQEKC0tTf7+/nbzzp07pwMHDigsLMzuN3VwDl4PFFbd55Y5u4Ry66BXlLNLKN8c9B/HK/UmFB29vow5ur3AWecuGDrwx18K2/CMvE4fKcWiyolyGk6VFPp98dHvr4FJen0FZxcAAAAAAABKD0EAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAGSXPx8ieUGrwMAoKTQY8oG28vA6wEATmXqIMDDw0OSdPbsWSdXAul/r0Pu6wIAwLWi15ctWTmSci7I7fwpZ5cCAKbm7uwCnMnNzU2VKlVSamqqJMnHx0cWi8XJVZmPYRg6e/asUlNTValSJbm5uTm7JACAi6DXO8GF/L/tzzGkv9LOySf1R7lnpZdyUQCAS5k6CJCk4OBgSbLtIMB5KlWqZHs9AABwFHp9KfvnrwJmGKqQcUK198yXRfw0AACcyalBQGxsrMaPH283FhQUpJSUFEkXvykeP3683nnnHZ08eVLt2rXTrFmz1LRpU4fVYLFYVKNGDQUGBur8+fMOWy+KxsPDgyMBAAAlgl5fymbek/94TrY8M1JVwbhQuvUAAPJw+hEBTZs21erVq223L/3P4JQpUzR16lTNnz9fDRo00MSJE9WlSxft2bNHfn5+Dq3Dzc2N/4gCAODC6PWl5PQRZ1cAALgKp58s0N3dXcHBwbapevXqki4eDTB9+nSNHTtWffv2VbNmzbRgwQKdPXtWCxcudHLVAAAAAACUT04PAvbu3auQkBCFhYXp/vvv1/79+yVJBw4cUEpKirp27Wpb1mq1KjIyUhs3bixwfZmZmUpPT7ebAAAAAADARU4NAtq1a6f3339fX3/9tebMmaOUlBRFRETo+PHjtvMEBAUF2d3n0nMI5Cc+Pl4BAQG2KTQ0tES3AQAAAACA8sSpQUD37t111113qXnz5urcubOWLVsmSVqwYIFtmcsv8WMYxhUv+zNmzBilpaXZpiNH+J0aAAAAAAC5nP7TgEtVrFhRzZs31969e22X+rn82//U1NQ8Rwlcymq1yt/f324CAAAAAAAXlakgIDMzU7t371aNGjUUFham4OBgJSUl2eZnZWVp3bp1ioiIcGKVAAAAAACUX04NAkaNGqV169bpwIED2rJli+6++26lp6dr4MCBslgsio6OVlxcnBYtWqT//Oc/GjRokHx8fBQVFeXMsgEAQBH88ccfeuCBB1S1alX5+PioVatW2rZtm22+YRiKjY1VSEiIvL291bFjR+3cudOJFQMA4Nrcnfngv//+u/r166e///5b1atX17///W9t3rxZderUkSTFxMQoIyNDw4cP18mTJ9WuXTutWrVKfn5+ziwbAAAU0smTJ3XjjTeqU6dOWrFihQIDA7Vv3z5VqlTJtsyUKVM0depUzZ8/Xw0aNNDEiRPVpUsX7dmzh54PAEAJcGoQkJCQcMX5FotFsbGxio2NLZ2CAACAQ02ePFmhoaGaN2+ebaxu3bq2fxuGoenTp2vs2LHq27evpIsnDQ4KCtLChQs1bNiw0i4ZAACXV6bOEQAAAFzLkiVL1LZtW91zzz0KDAxU69atNWfOHNv8AwcOKCUlRV27drWNWa1WRUZGauPGjfmuMzMzU+np6XYTAAAoPIIAAABQYvbv36/Zs2crPDxcX3/9tR599FE9+eSTev/99yX97+pAl18RKCgoKM+Vg3LFx8crICDANoWGhpbsRgAA4GIIAgAAQInJyclRmzZtFBcXp9atW2vYsGF6+OGHNXv2bLvlLBaL3W3DMPKM5RozZozS0tJs05EjR0qsfgAAXBFBAAAAKDE1atRQkyZN7MYaN26sw4cPS5KCg4MlKc+3/6mpqXmOEshltVrl7+9vNwEAgMIjCAAAACXmxhtv1J49e+zGfv31V9sVgsLCwhQcHKykpCTb/KysLK1bt04RERGlWisAAGbh1KsGAAAA1/b0008rIiJCcXFxuvfee/XDDz/onXfe0TvvvCPp4k8CoqOjFRcXp/DwcIWHhysuLk4+Pj6KiopycvUAALgmggAAAFBibrjhBi1atEhjxozRyy+/rLCwME2fPl39+/e3LRMTE6OMjAwNHz5cJ0+eVLt27bRq1Sr5+fk5sXIAAFwXQQAAAChRvXr1Uq9evQqcb7FYFBsbq9jY2NIrCgAAE+McAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJuLu7ALKm7rPLXN2CeXWwUk9nV0CAAAAAJgeRwQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAgBITGxsri8ViNwUHB9vmG4ah2NhYhYSEyNvbWx07dtTOnTudWDEAAK6PIAAAAJSopk2b6tixY7bpl19+sc2bMmWKpk6dqpkzZyo5OVnBwcHq0qWLTp065cSKAQBwbQQBAACgRLm7uys4ONg2Va9eXdLFowGmT5+usWPHqm/fvmrWrJkWLFigs2fPauHChU6uGgAA10UQAAAAStTevXsVEhKisLAw3X///dq/f78k6cCBA0pJSVHXrl1ty1qtVkVGRmrjxo0Fri8zM1Pp6el2EwAAKDyCAAAAUGLatWun999/X19//bXmzJmjlJQURURE6Pjx40pJSZEkBQUF2d0nKCjINi8/8fHxCggIsE2hoaElug0AALgaggAAAFBiunfvrrvuukvNmzdX586dtWzZMknSggULbMtYLBa7+xiGkWfsUmPGjFFaWpptOnLkSMkUDwCAiyIIAAAApaZixYpq3ry59u7da7t6wOXf/qempuY5SuBSVqtV/v7+dhMAACi8MhMExMfHy2KxKDo62jbGJYUAAHAtmZmZ2r17t2rUqKGwsDAFBwcrKSnJNj8rK0vr1q1TRESEE6sEAMC1lYkgIDk5We+8845atGhhN84lhQAAKN9GjRqldevW6cCBA9qyZYvuvvtupaena+DAgbYvAOLi4rRo0SL95z//0aBBg+Tj46OoqChnlw4AgMtyehBw+vRp9e/fX3PmzFHlypVt41xSCACA8u/3339Xv3791LBhQ/Xt21eenp7avHmz6tSpI0mKiYlRdHS0hg8frrZt2+qPP/7QqlWr5Ofn5+TKAQBwXe7OLuDxxx9Xz5491blzZ02cONE2frVLCg0bNizf9WVmZiozM9N2m0sKAQDgPAkJCVecb7FYFBsbq9jY2NIpCAAAODcISEhI0I8//qjk5OQ88650SaFDhw4VuM74+HiNHz/esYUCAAAAAOAinPbTgCNHjuipp57Shx9+KC8vrwKX45JCAAAAAAA4jtOOCNi2bZtSU1N1/fXX28ays7P13XffaebMmdqzZ4+ki0cG1KhRw7ZMYS4pZLVaS65wAAAAAADKMacdEXDrrbfql19+0Y4dO2xT27Zt1b9/f+3YsUP16tXjkkIAAAAAADiY044I8PPzU7NmzezGKlasqKpVq9rGcy8pFB4ervDwcMXFxXFJIQAAAAAAroHTrxpwJTExMcrIyNDw4cN18uRJtWvXjksKAQAAAABwDcpUELB27Vq721xSyMXEBji7gvIrNs3ZFQAAAABwEU47RwAAAAAAACh9BAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYSLGCgJUrV2r9+vW227NmzVKrVq0UFRWlkydPOqw4AADgPPR7AABcU7GCgGeffVbp6emSpF9++UXPPPOMevToof3792vkyJEOLRAAADgH/R4AANdUrCDgwIEDatKkiSTpiy++UK9evRQXF6c333xTK1ascGiBAADAOUqi38fHx8tisSg6Oto2ZhiGYmNjFRISIm9vb3Xs2FE7d+50xCYAAIB8FCsI8PT01NmzZyVJq1evVteuXSVJVapUsX1zAAAAyjdH9/vk5GS98847atGihd34lClTNHXqVM2cOVPJyckKDg5Wly5ddOrUqWvfCAAAkEexgoCbbrpJI0eO1IQJE/TDDz+oZ8+ekqRff/1VtWrVcmiBAADAORzZ70+fPq3+/ftrzpw5qly5sm3cMAxNnz5dY8eOVd++fdWsWTMtWLBAZ8+e1cKFCx26PQAA4KJiBQEzZ86Uu7u7Pv/8c82ePVs1a9aUJK1YsUK33XabQwsEAADO4ch+//jjj6tnz57q3Lmz3fiBAweUkpJiO9pAkqxWqyIjI7Vx48Z815WZman09HS7CQAAFJ57ce5Uu3ZtLV26NM/4tGnTrrkgAABQNjiq3yckJOjHH39UcnJynnkpKSmSpKCgILvxoKAgHTp0KN/1xcfHa/z48UWqAQAA/E+xjgiQpH379umFF15Qv379lJqaKuniZYY4uQ8AAK7jWvv9kSNH9NRTT+nDDz+Ul5dXgctZLBa724Zh5BnLNWbMGKWlpdmmI0eOFHJrAACAVMwgYN26dWrevLm2bNmixMREnT59WpL0888/a9y4cQ4tEAAAOIcj+v22bduUmpqq66+/Xu7u7nJ3d9e6dev0xhtvyN3d3XYkQO6RAblSU1PzHCWQy2q1yt/f324CAACFV6wg4LnnntPEiROVlJQkT09P23inTp20adMmhxUHAACcxxH9/tZbb9Uvv/yiHTt22Ka2bduqf//+2rFjh+rVq6fg4GAlJSXZ7pOVlaV169YpIiLC4dsEAACKeY6AX375Jd8z+VavXl3Hjx+/5qIAAIDzOaLf+/n5qVmzZnZjFStWVNWqVW3j0dHRiouLU3h4uMLDwxUXFycfHx9FRUVd+0YAAIA8ihUEVKpUSceOHVNYWJjd+Pbt221nFAYAAOVbafX7mJgYZWRkaPjw4Tp58qTatWunVatWyc/Pz2GPAQAA/qdYQUBUVJRGjx6tzz77TBaLRTk5OdqwYYNGjRqlAQMGOLpGAADgBCXV79euXWt322KxKDY2VrGxsddWMAAAKJRinSPglVdeUe3atVWzZk2dPn1aTZo00c0336yIiAi98MILjq4RAAA4Af0eAADXVKwjAjw8PPTRRx/p5Zdf1vbt25WTk6PWrVsrPDzc0fUBAAAnod8DAOCaihUE5Lruuut03XXXOaoWAABQBtHvAQBwLcUKAkaOHJnvuMVikZeXl+rXr6877rhDVapUuabiAACA89DvAQBwTcUKArZv364ff/xR2dnZatiwoQzD0N69e+Xm5qZGjRrpzTff1DPPPKP169erSZMmjq4ZAACUAvo9AACuqVgnC7zjjjvUuXNnHT16VNu2bdOPP/6oP/74Q126dFG/fv30xx9/6Oabb9bTTz/t6HoBAEApod8DAOCaihUEvPrqq5owYYL8/f1tY/7+/oqNjdWUKVPk4+Ojl156Sdu2bXNYoQAAoHTR7wEAcE3FCgLS0tKUmpqaZ/yvv/5Senq6JKlSpUrKysq6tuoAAIDT0O8BAHBNxf5pwJAhQ7Ro0SL9/vvv+uOPP7Ro0SI99NBD6tOnjyTphx9+UIMGDRxZKwAAKEX0ewAAXFOxThb49ttv6+mnn9b999+vCxcuXFyRu7sGDhyoadOmSZIaNWqkd99913GVAgCAUkW/BwDANRUrCPD19dWcOXM0bdo07d+/X4Zh6LrrrpOvr69tmVatWjmqRgAA4AT0ewAAXFOxfhqQy9fXVy1atFDLli3tdgoKa/bs2WrRooX8/f3l7++v9u3ba8WKFbb5hmEoNjZWISEh8vb2VseOHbVz585rKRkAABTRtfZ7AABQthTriABJSk5O1meffabDhw/nOUlQYmJiodZRq1YtTZo0SfXr15ckLViwQHfccYe2b9+upk2basqUKZo6darmz5+vBg0aaOLEierSpYv27NkjPz+/4pYOAAAKyRH9HgAAlC3FOiIgISFBN954o3bt2qVFixbp/Pnz2rVrl7799lsFBAQUej29e/dWjx491KBBAzVo0ECvvPKKfH19tXnzZhmGoenTp2vs2LHq27evmjVrpgULFujs2bNauHBhccoGAABF4Kh+DwAAypZiBQFxcXGaNm2ali5dKk9PT82YMUO7d+/Wvffeq9q1axerkOzsbCUkJOjMmTNq3769Dhw4oJSUFHXt2tW2jNVqVWRkpDZu3FjgejIzM5Wenm43AQCAoiuJfg8AAJyvWEHAvn371LNnT0kX/3N+5swZWSwWPf3003rnnXeKtK5ffvlFvr6+slqtevTRR7Vo0SI1adJEKSkpkqSgoCC75YOCgmzz8hMfH6+AgADbFBoaWsStAwAAkmP7PQAAKDuKFQRUqVJFp06dkiTVrFlT//nPfyRJ//zzj86ePVukdTVs2FA7duzQ5s2b9dhjj2ngwIHatWuXbb7FYrFb3jCMPGOXGjNmjNLS0mzTkSNHilQPAAC4yJH9HgAAlB3FOllghw4dlJSUpObNm+vee+/VU089pW+//VZJSUm69dZbi7QuT09P28kC27Ztq+TkZM2YMUOjR4+WJKWkpKhGjRq25VNTU/McJXApq9Uqq9VajK0CAACXcmS/BwAAZUexgoCZM2fq3Llzki5+A+/h4aH169erb9++evHFF6+pIMMwlJmZqbCwMAUHByspKUmtW7eWJGVlZWndunWaPHnyNT0GAAC4upLs9wAAwHmKFQRUqVLF9u8KFSooJiZGMTExRV7P888/r+7duys0NFSnTp1SQkKC1q5dq5UrV8pisSg6OlpxcXEKDw9XeHi44uLi5OPjo6ioqOKUDQAAisBR/R4AAJQtxQoC3NzcdOzYMQUGBtqNHz9+XIGBgcrOzi7Uev788089+OCDOnbsmAICAtSiRQutXLlSXbp0kSTFxMQoIyNDw4cP18mTJ9WuXTutWrVKfn5+xSkbAAAUgaP6PQAAKFuKFQQYhpHveGZmpjw9PQu9nrlz515xvsViUWxsrGJjY4tSHgAAcABH9XsAAFC2FCkIeOONNyRd/A/6u+++K19fX9u87Oxsfffdd2rUqJFjKwQAAKWKfg8AgGsrUhAwbdo0SRe/IXjrrbfk5uZmm+fp6am6devqrbfecmyFAACgVNHvAQBwbUUKAg4cOCBJ6tSpkxITE1W5cuUSKQoAADgP/R4AANdWrHMErFmzxtF1AACAMoZ+DwCAaypWEJCdna358+frm2++UWpqqnJycuzmf/vttw4pDgAAOA/9HgAA11SsIOCpp57S/Pnz1bNnTzVr1kwWi8XRdQEAACej3wMA4JqKFQQkJCTo008/VY8ePRxdDwAAKCPo9wAAuKYKxbmTp6en6tev7+haAABAGUK/BwDANRUrCHjmmWc0Y8YMGYbh6HoAAEAZQb8HAMA1FeunAevXr9eaNWu0YsUKNW3aVB4eHnbzExMTHVIcAABwHvo9AACuqVhBQKVKlXTnnXc6uhYAAFCG0O8BAHBNxQoC5s2b5+g6AABAGUO/BwDANRXrHAGSdOHCBa1evVpvv/22Tp06JUk6evSoTp8+7bDiAACAc9HvAQBwPcU6IuDQoUO67bbbdPjwYWVmZqpLly7y8/PTlClTdO7cOb311luOrhMAAJQy+j0AAK6pWEcEPPXUU2rbtq1Onjwpb29v2/idd96pb775xmHFAQAA56HfAwDgmop91YANGzbI09PTbrxOnTr6448/HFIYAABwLvo9AACuqVhHBOTk5Cg7OzvP+O+//y4/P79rLgoAADgf/R4AANdUrCCgS5cumj59uu22xWLR6dOnNW7cOPXo0cNRtQEAACei3wMA4JqK9dOAadOmqVOnTmrSpInOnTunqKgo7d27V9WqVdPHH3/s6BoBAIAT0O8BAHBNxQoCQkJCtGPHDiUkJGjbtm3KycnRQw89pP79+9udTAgAAJRf9HsAAFxTsYIASfL29tbgwYM1ePBgR9YDAADKEPo9AACup1jnCIiPj9d7772XZ/y9997T5MmTr7koAADgfPR7AABcU7GCgLfffluNGjXKM960aVO99dZb11wUAABwPvo9AACuqVhBQEpKimrUqJFnvHr16jp27Ng1FwUAAJyPfg8AgGsqVhAQGhqqDRs25BnfsGGDQkJCrrkoAADgfPR7AABcU7FOFjh06FBFR0fr/PnzuuWWWyRJ33zzjWJiYvTMM884tEAAAOAc9HsAAFxTsYKAmJgYnThxQsOHD1dWVpYkycvLS6NHj9aYMWMcWiAAAHAO+j0AAK6pyEFAdna21q9fr9GjR+vFF1/U7t275e3trfDwcFmt1pKoEQAAlDL6PQAArqvIQYCbm5u6deum3bt3KywsTDfccENJ1AUAAJyIfg8AgOsq1skCmzdvrv379zu6FgAAUIbQ7wEAcE3FCgJeeeUVjRo1SkuXLtWxY8eUnp5uNwEAgPKPfg8AgGsq1skCb7vtNknS7bffLovFYhs3DEMWi0XZ2dmOqQ4AADgN/R4AANdUrCBgzZo1jq4DAACUMfR7AABcU7GCgMjISEfXAQAAyhhH9PvZs2dr9uzZOnjwoCSpadOmeumll9S9e3dJF48uGD9+vN555x2dPHlS7dq106xZs9S0adNrfmwAAJC/Yp0jQJK+//57PfDAA4qIiNAff/whSfrggw+0fv16hxUHAACc61r7fa1atTRp0iRt3bpVW7du1S233KI77rhDO3fulCRNmTJFU6dO1cyZM5WcnKzg4GB16dJFp06dKrFtAgDA7IoVBHzxxRfq1q2bvL299eOPPyozM1OSdOrUKcXFxTm0QAAA4ByO6Pe9e/dWjx491KBBAzVo0ECvvPKKfH19tXnzZhmGoenTp2vs2LHq27evmjVrpgULFujs2bNauHBhSW4aAACmVqwgYOLEiXrrrbc0Z84ceXh42MYjIiL0448/Oqw4AADgPI7u99nZ2UpISNCZM2fUvn17HThwQCkpKeratattGavVqsjISG3cuLHA9WRmZnIFAwAArkGxgoA9e/bo5ptvzjPu7++vf/7551prAgAAZYCj+v0vv/wiX19fWa1WPfroo1q0aJGaNGmilJQUSVJQUJDd8kFBQbZ5+YmPj1dAQIBtCg0NLXQtAACgmEFAjRo19Ntvv+UZX79+verVq3fNRQEAAOdzVL9v2LChduzYoc2bN+uxxx7TwIEDtWvXLtv8Sy9NKP3v8oQFGTNmjNLS0mzTkSNHCl0LAAAoZhAwbNgwPfXUU9qyZYssFouOHj2qjz76SKNGjdLw4cMdXSMAAHACR/V7T09P1a9fX23btlV8fLxatmypGTNmKDg4WJLyfPufmpqa5yiBS1mtVvn7+9tNAACg8Ip1+cCYmBilp6erU6dOOnfunG6++WZZrVaNGjVKI0aMcHSNAADACUqq3xuGoczMTIWFhSk4OFhJSUlq3bq1JCkrK0vr1q3T5MmTHbUZAADgMkUKAs6ePatnn31Wixcv1vnz59W7d28988wzkqQmTZrI19e3RIoEAAClx5H9/vnnn1f37t0VGhqqU6dOKSEhQWvXrtXKlStlsVgUHR2tuLg4hYeHKzw8XHFxcfLx8VFUVFRJbR4AAKZXpCBg3Lhxmj9/vvr37y9vb28tXLhQOTk5+uyzz0qqPgAAUMoc2e///PNPPfjggzp27JgCAgLUokULrVy5Ul26dJF08aiDjIwMDR8+XCdPnlS7du20atUq+fn5OXqzAADA/1ekICAxMVFz587V/fffL0nq37+/brzxRmVnZ8vNza1ECgQAAKXLkf1+7ty5V5xvsVgUGxur2NjY4pYLAACKqEgnCzxy5Ig6dOhgu/2vf/1L7u7uOnr0qMMLAwAAzkG/BwDAtRUpCMjOzpanp6fdmLu7uy5cuODQogAAgPPQ7wEAcG1F+mmAYRgaNGiQrFarbezcuXN69NFHVbFiRdtYYmKi4yoEAAClin4PAIBrK1IQMHDgwDxjDzzwgMOKAQAAzke/BwDAtRUpCJg3b15J1QEAAMoI+j0AAK6tSOcIAAAAAAAA5RtBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiTg0C4uPjdcMNN8jPz0+BgYHq06eP9uzZY7eMYRiKjY1VSEiIvL291bFjR+3cudNJFQMAAAAAUL45NQhYt26dHn/8cW3evFlJSUm6cOGCunbtqjNnztiWmTJliqZOnaqZM2cqOTlZwcHB6tKli06dOuXEygEAAAAAKJ/cnfngK1eutLs9b948BQYGatu2bbr55ptlGIamT5+usWPHqm/fvpKkBQsWKCgoSAsXLtSwYcOcUTYAAAAAAOVWmTpHQFpamiSpSpUqkqQDBw4oJSVFXbt2tS1jtVoVGRmpjRs35ruOzMxMpaen200AAAAAAOCiMhMEGIahkSNH6qabblKzZs0kSSkpKZKkoKAgu2WDgoJs8y4XHx+vgIAA2xQaGlqyhQMAAAAAUI6UmSBgxIgR+vnnn/Xxxx/nmWexWOxuG4aRZyzXmDFjlJaWZpuOHDlSIvUCAAAAAFAeOfUcAbmeeOIJLVmyRN99951q1aplGw8ODpZ08ciAGjVq2MZTU1PzHCWQy2q1ymq1lmzBAAAAAACUU049IsAwDI0YMUKJiYn69ttvFRYWZjc/LCxMwcHBSkpKso1lZWVp3bp1ioiIKO1yAQAAAAAo95x6RMDjjz+uhQsX6ssvv5Sfn5/td/8BAQHy9vaWxWJRdHS04uLiFB4ervDwcMXFxcnHx0dRUVHOLB0AAAAAgHLJqUHA7NmzJUkdO3a0G583b54GDRokSYqJiVFGRoaGDx+ukydPql27dlq1apX8/PxKuVoAAAAAAMo/pwYBhmFcdRmLxaLY2FjFxsaWfEEAAAAAALi4MnPVAAAAAAAAUPIIAgAAAAAAMBGCAAAAAAAATIQgAAAAAAAAEyEIAAAAAADARAgCAAAAAAAwEYIAAAAAAABMhCAAAAAAAAATIQgAAAAAAMBECAIAAAAAADARggAAAAAAAEyEIAAAAAAAABMhCAAAAAAAwEQIAgAAAAAAMBGCAAAAAAAATIQgAAAAAAAAEyEIAAAAAADARAgCAAAAAAAwEYIAAAAAAABMhCAAAACUmPj4eN1www3y8/NTYGCg+vTpoz179tgtYxiGYmNjFRISIm9vb3Xs2FE7d+50UsUAALg+ggAAAFBi1q1bp8cff1ybN29WUlKSLly4oK5du+rMmTO2ZaZMmaKpU6dq5syZSk5OVnBwsLp06aJTp045sXIAAFyXu7MLAAAArmvlypV2t+fNm6fAwEBt27ZNN998swzD0PTp0zV27Fj17dtXkrRgwQIFBQVp4cKFGjZsmDPKBgDApXFEAAAAKDVpaWmSpCpVqkiSDhw4oJSUFHXt2tW2jNVqVWRkpDZu3JjvOjIzM5Wenm43AQCAwiMIAAAApcIwDI0cOVI33XSTmjVrJklKSUmRJAUFBdktGxQUZJt3ufj4eAUEBNim0NDQki0cAAAXQxAAAABKxYgRI/Tzzz/r448/zjPPYrHY3TYMI89YrjFjxigtLc02HTlypETqBQDAVXGOAAAAUOKeeOIJLVmyRN99951q1aplGw8ODpZ08ciAGjVq2MZTU1PzHCWQy2q1ymq1lmzBAAC4MI4IAAAAJcYwDI0YMUKJiYn69ttvFRYWZjc/LCxMwcHBSkpKso1lZWVp3bp1ioiIKO1yAQAwBY4IAAAAJebxxx/XwoUL9eWXX8rPz8/2u/+AgAB5e3vLYrEoOjpacXFxCg8PV3h4uOLi4uTj46OoqCgnVw8AgGsiCAAAACVm9uzZkqSOHTvajc+bN0+DBg2SJMXExCgjI0PDhw/XyZMn1a5dO61atUp+fn6lXC0AAOZAEAAAAEqMYRhXXcZisSg2NlaxsbElXxAAAOAcAQAAAAAAmAlBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIk4NAr777jv17t1bISEhslgsWrx4sd18wzAUGxurkJAQeXt7q2PHjtq5c6dzigUAAAAAwAU4NQg4c+aMWrZsqZkzZ+Y7f8qUKZo6dapmzpyp5ORkBQcHq0uXLjp16lQpVwoAAAAAgGtwd+aDd+/eXd27d893nmEYmj59usaOHau+fftKkhYsWKCgoCAtXLhQw4YNK81SAQAAAABwCWX2HAEHDhxQSkqKunbtahuzWq2KjIzUxo0bC7xfZmam0tPT7SYAAAAAAHBRmQ0CUlJSJElBQUF240FBQbZ5+YmPj1dAQIBtCg0NLdE6AQAAAAAoT8psEJDLYrHY3TYMI8/YpcaMGaO0tDTbdOTIkZIuEQAAAACAcsOp5wi4kuDgYEkXjwyoUaOGbTw1NTXPUQKXslqtslqtJV4fAAAAAADlUZk9IiAsLEzBwcFKSkqyjWVlZWndunWKiIhwYmUAAAAAAJRfTj0i4PTp0/rtt99stw8cOKAdO3aoSpUqql27tqKjoxUXF6fw8HCFh4crLi5OPj4+ioqKcmLVAAAAAACUX04NArZu3apOnTrZbo8cOVKSNHDgQM2fP18xMTHKyMjQ8OHDdfLkSbVr106rVq2Sn5+fs0oGAAAAAKBcc2oQ0LFjRxmGUeB8i8Wi2NhYxcbGll5RAAAAAAC4sDJ7jgAAAAAAAOB4BAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAgBLz3XffqXfv3goJCZHFYtHixYvt5huGodjYWIWEhMjb21sdO3bUzp07nVMsAAAmQRAAAABKzJkzZ9SyZUvNnDkz3/lTpkzR1KlTNXPmTCUnJys4OFhdunTRqVOnSrlSAADMw6mXDwQAAK6te/fu6t69e77zDMPQ9OnTNXbsWPXt21eStGDBAgUFBWnhwoUaNmxYaZYKAIBpcEQAAABwigMHDiglJUVdu3a1jVmtVkVGRmrjxo0F3i8zM1Pp6el2EwAAKDyCAAAA4BQpKSmSpKCgILvxoKAg27z8xMfHKyAgwDaFhoaWaJ0AALgaggAAAOBUFovF7rZhGHnGLjVmzBilpaXZpiNHjpR0iQAAuBTOEQAAAJwiODhY0sUjA2rUqGEbT01NzXOUwKWsVqusVmuJ1wcAgKviiAAAAOAUYWFhCg4OVlJSkm0sKytL69atU0REhBMrAwDAtXFEAAAAKDGnT5/Wb7/9Zrt94MAB7dixQ1WqVFHt2rUVHR2tuLg4hYeHKzw8XHFxcfLx8VFUVJQTqwYAwLURBAAAgBKzdetWderUyXZ75MiRkqSBAwdq/vz5iomJUUZGhoYPH66TJ0+qXbt2WrVqlfz8/JxVMgAALo8gAAAAlJiOHTvKMIwC51ssFsXGxio2Nrb0igIAwOQ4RwAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIgQBAAAAAACYCEEAAAAAAAAmQhAAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAAAAAACAiRAEAAAAAABgIuUiCHjzzTcVFhYmLy8vXX/99fr++++dXRIAAHAw+j0AAKWjzAcBn3zyiaKjozV27Fht375dHTp0UPfu3XX48GFnlwYAAByEfg8AQOkp80HA1KlT9dBDD2no0KFq3Lixpk+frtDQUM2ePdvZpQEAAAeh3wMAUHrcnV3AlWRlZWnbtm167rnn7Ma7du2qjRs35nufzMxMZWZm2m6npaVJktLT0x1SU07mWYesx4zSLYazSyi/HPT+dRV8DouPz+E1ctBnMbcnGQavh1T0fl/SvR7XKJP3dbHxHrZDvy8++v01MEmvL9NBwN9//63s7GwFBQXZjQcFBSklJSXf+8THx2v8+PF5xkNDQ0ukRhRegLMLKM8m8ezBMXgnXSMHfxZPnTqlgABelaL2e3o9XBb9Hg7CO+kamKTXl+kgIJfFYrG7bRhGnrFcY8aM0ciRI223c3JydOLECVWtWrXA+6DkpaenKzQ0VEeOHJG/v7+zywFMic9h2WEYhk6dOqWQkBBnl1KmFLbf0+vLLv7OAM7H57BsKOu9vkwHAdWqVZObm1uebwNSU1PzfGuQy2q1ymq12o1VqlSppEpEEfn7+/MHCXAyPodlQ1n8dsBZitrv6fVlH39nAOfjc+h8ZbnXl+mTBXp6eur6669XUlKS3XhSUpIiIiKcVBUAAHAk+j0AAKWrTB8RIEkjR47Ugw8+qLZt26p9+/Z65513dPjwYT366KPOLg0AADgI/R4AgNJT5oOA++67T8ePH9fLL7+sY8eOqVmzZlq+fLnq1Knj7NJQBFarVePGjctzKCeA0sPnEGUZ/d418HcGcD4+hygMi1FWr2cAAAAAAAAcrkyfIwAAAAAAADgWQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAXAYi8VyxWnQoEF5lvPz81Pbtm2VmJjo3OIBF1CUz6CXl5cOHTpkd/8+ffrYlgGA/NDrAeei18NRCALgMMeOHbNN06dPl7+/v93YjBkzbMvOmzdPx44dU3Jyslq2bKl77rlHmzZtcmL1QPlXlM+gxWLRSy+95MRqAZRH9HrAuej1cBSCADhMcHCwbQoICJDFYskzlqtSpUoKDg5Wo0aN9NZbb8nLy0tLlixxYvVA+VeUz+ATTzyhDz/8UL/88osTKwZQ3tDrAeei18NRCALgdB4eHnJ3d9f58+edXQpgGhEREerVq5fGjBnj7FIAmAC9Hih99HpcCUEAnCozM1MTJ05Uenq6br31VmeXA5hKfHy8Vq5cqe+//97ZpQBwYfR6wHno9SiIu7MLgDn169dPbm5uysjIUEBAgF577TV1797d2WUBptKkSRMNGDBAo0eP1saNG51dDgAXQ68HnI9ej4IQBMAppk2bps6dO8vf31+BgYHOLgcwrfHjx6tBgwZavHixs0sB4GLo9UDZQK9HfvhpAJwiODhY9evXZ8cAcLLQ0FCNGDFCzz//vLKzs51dDgAXQq8HygZ6PfJDEAAAJjdmzBgdPXpUq1evdnYpAACgBNDrcTmCAAAwuSpVqmj06NE6d+6cs0sBAAAlgF6Py1kMwzCcXQQAAAAAACgdHBEAAAAAAICJEAQAAAAAAGAiBAEAAAAAAJgIQQAAAAAAACZCEAAAAAAAgIkQBAAAAAAAYCIEAQAAAAAAmAhBAAAAAAAAJkIQAMBhLBaLFi9e7OwyAABACaHXA66BIABwMYMGDZLFYtGjjz6aZ97w4cNlsVg0aNCgQq1r7dq1slgs+ueffwq1/LFjx9S9e/ciVAsAAIqKXg/gWhEEAC4oNDRUCQkJysjIsI2dO3dOH3/8sWrXru3wx8vKypIkBQcHy2q1Onz9AADAHr0ewLUgCABcUJs2bVS7dm0lJibaxhITExUaGqrWrVvbxgzD0JQpU1SvXj15e3urZcuW+vzzzyVJBw8eVKdOnSRJlStXtvt2oWPHjhoxYoRGjhypatWqqUuXLpLyHi74+++/6/7771eVKlVUsWJFtW3bVlu2bJEk/fTTT+rUqZP8/Pzk7++v66+/Xlu3bi3JpwUAAJdBrwdwLdydXQCAkjF48GDNmzdP/fv3lyS99957GjJkiNauXWtb5oUXXlBiYqJmz56t8PBwfffdd3rggQdUvXp13XTTTfriiy901113ac+ePfL395e3t7ftvgsWLNBjjz2mDRs2yDCMPI9/+vRpRUZGqmbNmlqyZImCg4P1448/KicnR5LUv39/tW7dWrNnz5abm5t27NghDw+Pkn1SAABwIfR6AMVFEAC4qAcffFBjxozRwYMHZbFYtGHDBiUkJNh2Ds6cOaOpU6fq22+/Vfv27SVJ9erV0/r16/X2228rMjJSVapUkSQFBgaqUqVKduuvX7++pkyZUuDjL1y4UH/99ZeSk5Nt66lfv75t/uHDh/Xss8+qUaNGkqTw8HBHbToAAKZArwdQXAQBgIuqVq2aevbsqQULFsgwDPXs2VPVqlWzzd+1a5fOnTtnO9QvV1ZWlt0hhQVp27btFefv2LFDrVu3tu0YXG7kyJEaOnSoPvjgA3Xu3Fn33HOPrrvuukJsGQAAkOj1AIqPIABwYUOGDNGIESMkSbNmzbKbl3vY3rJly1SzZk27eYU5CVDFihWvOP/SQwvzExsbq6ioKC1btkwrVqzQuHHjlJCQoDvvvPOqjw0AAC6i1wMoDk4WCLiw2267TVlZWcrKylK3bt3s5jVp0kRWq1WHDx9W/fr17abQ0FBJkqenpyQpOzu7yI/dokUL7dixQydOnChwmQYNGujpp5/WqlWr1LdvX82bN6/IjwMAgJnR6wEUB0EA4MLc3Ny0e/du7d69W25ubnbz/Pz8NGrUKD399NNasGCB9u3bp+3bt2vWrFlasGCBJKlOnTqyWCxaunSp/vrrL50+fbrQj92vXz8FBwerT58+2rBhg/bv368vvvhCmzZtUkZGhkaMGKG1a9fq0KFD2rBhg5KTk9W4cWOHbj8AAK6OXg+gOAgCABfn7+8vf3//fOdNmDBBL730kuLj49W4cWN169ZNX331lcLCwiRJNWvW1Pjx4/Xcc88pKCjIduhhYXh6emrVqlUKDAxUjx491Lx5c02aNElubm5yc3PT8ePHNWDAADVo0ED33nuvunfvrvHjxztkmwEAMBN6PYCishj5XQsEAAAAAAC4JI4IAAAAAADARAgCAAAAAAAwEYIAAAAAAABMhCAAAAAAAAATIQgAAAAAAMBECAIAAAAAADARggAAAAAAAEyEIAAAAAAAABMhCAAAAAAAwEQIAgAAAAAAMBGCAAAAAAAATOT/AbN85EBK07O8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "TP_male = [13, 0]\n",
    "TP_female = [11, 2]\n",
    "TP_general = [28, 3]\n",
    "\n",
    "TN_male = [24, 4]\n",
    "TN_female = [24, 4]\n",
    "TN_general = [44, 6]\n",
    "\n",
    "TP_male_percentage = [TP_male[0] / TP_general[0] * 100, TP_male[1] / TP_general[1] * 100]\n",
    "TP_female_percentage = [TP_female[0] / TP_general[0] * 100, TP_female[1] / TP_general[1] * 100]\n",
    "TN_male_percentage = [TN_male[0] / TN_general[0] * 100, TN_male[1] / TN_general[1] * 100]\n",
    "TN_female_percentage = [TN_female[0] / TN_general[0] * 100, TN_female[1] / TN_general[1] * 100]\n",
    "\n",
    "datasets = ['Training', 'Test']\n",
    "metrics = ['TP', 'TN']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    ax = axes[i]\n",
    "\n",
    "    proportions_male = [TP_male_percentage[i], TN_male_percentage[i]]\n",
    "    proportions_female = [TP_female_percentage[i], TN_female_percentage[i]]\n",
    "\n",
    "    x = np.arange(len(metrics))\n",
    "    bar_width = 0.35\n",
    "\n",
    "    ax.bar(x - bar_width/2, proportions_male, bar_width, label='Male')\n",
    "    ax.bar(x + bar_width/2, proportions_female, bar_width, label='Female')\n",
    "\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Percentages')\n",
    "    ax.set_title(f'TP and TN values compared to General values ({dataset} Data)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** Proportion of correct prediction out of total prediction of the training/testing data.\n",
    "- The higher the better\n",
    "<br>\n",
    "\n",
    "**Loss:** Measures the difference between the predicted and true output of the training/testing data. \n",
    "- The lower the better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
